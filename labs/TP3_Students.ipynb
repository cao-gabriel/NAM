{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 (Teacher version): robustness of a graph \n",
    "\n",
    "We can use the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "from random import *\n",
    "from collections import deque\n",
    "import copy, random\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session, we investigate the notion of robustness of a graph: how well a graph remains connected when nodes disappear following random failures or degree-based failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: preliminary work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using the code seen in previous labs, load the following graph as a dictonary of lists:\n",
    "\n",
    "http://lioneltabourier.fr/documents/inet.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_loop_dupes(graph):\n",
    "    for node in graph:\n",
    "        graph[node] = list(dict.fromkeys(graph[node]))\n",
    "        try:\n",
    "            graph[node].remove(node)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "def graph_from_file(file_name):\n",
    "    graph = {}\n",
    "    with open(file_name, \"r\") as graph_file:\n",
    "        for line in graph_file:\n",
    "            try:\n",
    "                node1, node2 = [int(node) for node in line.split()]\n",
    "                if node1 not in graph:\n",
    "                    graph[node1] = []\n",
    "                graph[node1].append(node2)\n",
    "                if node2 not in graph:\n",
    "                    graph[node2]= []\n",
    "                graph[node2].append(node1)\n",
    "            except:\n",
    "                pass\n",
    "    remove_loop_dupes(graph)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def graph_to_file(graph, file_name):\n",
    "    with open(file_name, \"w\") as graph_file:\n",
    "        for node1 in graph:\n",
    "            for node2 in graph[node1]:\n",
    "                graph_file.write(\"{} {}\\n\".format(node1, node2))\n",
    "def count_links(graph):\n",
    "    link_count = 0\n",
    "    for node in graph:\n",
    "        link_count += len(graph[node])\n",
    "    return link_count\n",
    "def compute_degree_dist(graph):\n",
    "    degree_dist = {}\n",
    "    for node in graph:\n",
    "        degree = len(graph[node])\n",
    "        if degree not in degree_dist:\n",
    "            degree_dist[degree] = 0\n",
    "        degree_dist[degree] += 1\n",
    "    return degree_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Determine the size of the largest connected component (LCC) of a graph, and use the code to determine the size of the LCC of the example graph.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- Create a function that takes a graph as input and outputs a dictionary of the connected component that each node belongs to. (This function is derived from a BFS).\n",
    "\n",
    "- Then, create another function which takes the dictionary of the connected component as input and computes the size of the largest connected component of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, node_start):\n",
    "    queue = [node_start]\n",
    "    marked = [node_start]\n",
    "    while queue:\n",
    "        node1 = queue.pop(0)\n",
    "        for node2 in graph[node1]:\n",
    "            if node2 not in marked:\n",
    "                queue.append(node2)\n",
    "                marked.append(node2)\n",
    "    return marked\n",
    "\n",
    "def compute_size_lcc(graph):\n",
    "    nodes_cc_index = {}\n",
    "    cc_index = 0\n",
    "    cc_sizes = []\n",
    "    for node in graph:\n",
    "        nodes_cc_index[node] = -1\n",
    "    for node in graph:\n",
    "        if nodes_cc_index[node] == -1:\n",
    "            cc = bfs(graph, node)\n",
    "            cc_sizes.append(len(cc))\n",
    "            for node_marked in cc:\n",
    "                nodes_cc_index[node_marked] = cc_index\n",
    "            cc_index += 1\n",
    "    return max(cc_sizes)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: robustness to random failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In this question, we plot the size of the LCC as a function of the number of nodes which removed. This is a way to evaluate the robustness of the network to random failures.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- create a function that deletes $n_s$ nodes from the original graph\n",
    "\n",
    "- use the function of question 2 to compute the size of the LCC\n",
    "\n",
    "- combine these two functions and iterate to get a dictionary which keys are $n_s$ and values are the corresponding size of the LCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nodes(graph, nodes_deleted):\n",
    "    tmp = copy.deepcopy(graph)\n",
    "    for node1 in nodes_deleted:\n",
    "        for node2 in tmp[node1]:\n",
    "\n",
    "            tmp[node2].remove(node1)\n",
    "        tmp.pop(node1)\n",
    "\n",
    "    return tmp\n",
    "\n",
    "def random_failure(graph, max_deleted=8000, step=100):\n",
    "    robust_dic = {}\n",
    "    for n in range(0, max_deleted, step):\n",
    "        nodes = list(graph.keys())\n",
    "        random.shuffle(nodes)\n",
    "        tmp = remove_nodes(graph, nodes[0:n])\n",
    "        lcc_size = compute_size_lcc(tmp)\n",
    "        robust_dic[n] = lcc_size\n",
    "    return robust_dic\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet_graph = graph_from_file(\"res/inet.txt\")\n",
    "random_failure(inet_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: robustness to targeted (degree-based) failures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "In this question, we do the same as in the previous question, except for the fact that nodes are not chosen randomly, but by decreasing degree order.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- create a function that outputs a list of nodes ordered by decreasing degree\n",
    "\n",
    "- then follow the same principle as in the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_nodes(graph):\n",
    "    nodes = list(graph.keys())\n",
    "    node_degree = {}\n",
    "    for node in graph:\n",
    "        node_degree[node] = len(graph[node])\n",
    "    return [node for node, degree in sorted(node_degree.items(), key=lambda x : x[1], reverse=True)]\n",
    "\n",
    "def targeted_failure(graph, max_deleted=8000, step=100):\n",
    "    robust_dic = {}\n",
    "    for n in range(0, max_deleted, step):\n",
    "        nodes =  order_nodes(graph)\n",
    "        tmp = remove_nodes(graph, nodes[0:n])\n",
    "        lcc_size = compute_size_lcc(tmp)\n",
    "        robust_dic[n] = lcc_size\n",
    "    return robust_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targeted_failure(inet_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the two curves (random deletions and targeted deletions): are they different? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_dic = random_failure(inet_graph)\n",
    "targeted_dic = targeted_failure(inet_graph)\n",
    "x_random, y_random = random_dic.keys(), random_dic.values()\n",
    "x_target, y_target = targeted_dic.keys(), targeted_dic.values()\n",
    "plt.plot(x_random, y_random)\n",
    "plt.plot(x_target, y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
