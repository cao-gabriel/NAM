{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab3 (Teacher version): robustness of a graph \n",
    "\n",
    "We can use the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import json\n",
    "from random import *\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab session, we investigate the notion of robustness of a graph: how well a graph remains connected when nodes disappear following random failures or degree-based failures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: preliminary work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Using the code seen in previous labs, load the following graph as a dictonary of lists:\n",
    "\n",
    "http://lioneltabourier.fr/documents/inet.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_graph(input_name, output_name = None):\n",
    "    '''\n",
    "    load_clean_graph(input_name, output_name = None)\n",
    "    \n",
    "    Delete self-loops and duplicated edges existing in the graph and writes it in a new test file\"\n",
    "        Parameters:\n",
    "            input_name (string) : name of the file storing the graph with self loops and duplicated edges\n",
    "            output_name (string) (optional) : name of the file that will store the graph without self \n",
    "            loops and duplicated edges. If no output is defined the new graph will not be stored in a file\n",
    "        Returns:\n",
    "            my_graph (dictionary of lists) : the graph without self loops and duplicated edges\n",
    "    '''\n",
    "    my_graph = {}\n",
    "    if output_name is not None:\n",
    "        output_file = open(output_name, \"w\")\n",
    "    with open(input_name, \"r\") as input_file:\n",
    "        for line in input_file:\n",
    "\n",
    "            if line[0] != \"#\":\n",
    "                line = line.split()\n",
    "                node1 = int(line[0])\n",
    "                node2 = int(line[1])\n",
    "                if node1 != node2:\n",
    "                    if node1 in my_graph:\n",
    "                        if node2 not in my_graph[node1]:\n",
    "                            my_graph[node1].append(node2)\n",
    "                            if output_name is not None:\n",
    "                                output_file.write(f\"{node1} {node2}\\n\")\n",
    "                    else:\n",
    "                        my_graph[node1] = [node2]\n",
    "                    if node2 in my_graph:\n",
    "                        if node1 not in my_graph[node2]:\n",
    "                            my_graph[node2].append(node1)\n",
    "                            if output_name is not None:\n",
    "                                output_file.write(f\"{node2} {node1}\\n\")\n",
    "                    else:\n",
    "                        my_graph[node2] = [node1]\n",
    "    if output_name is not None:\n",
    "        output_file.close()\n",
    "    return my_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inet = \"graphs/inet.txt\"\n",
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    inet_graph = load_clean_graph(inet)\n",
    "    print(json.dumps(inet_graph, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Determine the size of the largest connected component (LCC) of a graph, and use the code to determine the size of the LCC of the example graph.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- Create a function that takes a graph as input and outputs a dictionary of the connected component that each node belongs to. (This function is derived from a BFS).\n",
    "\n",
    "- Then, create another function which takes the dictionary of the connected component as input and computes the size of the largest connected component of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(my_graph):\n",
    "    '''\n",
    "    bfs(my_graph)\n",
    "    \n",
    "    Evaluate the size of the largest connect component of the graph 'my_graph' by going through all nodes of the \n",
    "    graph and identifying the connected component that contains the node\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "        Returns:\n",
    "            my_lcc : the size of the largest connected component of 'my_graph'\n",
    "    '''\n",
    "    my_cc = {}\n",
    "    cc_index = 0\n",
    "    for source in my_graph.keys():\n",
    "        if source not in my_cc:\n",
    "            my_queue = [source]\n",
    "            marked_node = [source]\n",
    "            while my_queue:\n",
    "                node1 = my_queue.pop(0)\n",
    "                my_cc[node1] = cc_index\n",
    "                for node2 in my_graph[node1]:\n",
    "                    if node2 not in marked_node:\n",
    "                        my_queue.append(node2)\n",
    "                        marked_node.append(node2)\n",
    "            cc_index += 1\n",
    "    \n",
    "    cc_sizes = {}\n",
    "    for node in my_cc:\n",
    "        cc_index = my_cc[node]\n",
    "        if cc_index in cc_sizes:\n",
    "            cc_sizes[cc_index] += 1\n",
    "        else:\n",
    "            cc_sizes[cc_index] = 1\n",
    "    return max(list(cc_sizes.values()))\n",
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    lcc_size = bfs(inet_graph)\n",
    "    print(f\"Size of largest connected component in the graph 'inet' : {lcc_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: robustness to random failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "In this question, we plot the size of the LCC as a function of the number of nodes which removed. This is a way to evaluate the robustness of the network to random failures.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- create a function that deletes $n_s$ nodes from the original graph\n",
    "\n",
    "- use the function of question 2 to compute the size of the LCC\n",
    "\n",
    "- combine these two functions and iterate to get a dictionary which keys are $n_s$ and values are the corresponding size of the LCC\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_node(my_graph, nodes):\n",
    "    '''\n",
    "    delete_node(my_graph, nodes)\n",
    "    \n",
    "    Deletes the nodes 'nodes' from the graph 'my_graph'\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            nodes (list) : list of nodes to be deleted\n",
    "        Return:\n",
    "        \n",
    "    '''\n",
    "    for node1 in nodes:\n",
    "        for node2 in my_graph[node1]:\n",
    "            my_graph[node2].remove(node1)\n",
    "            #TODO catch exception if remove fail\n",
    "        my_graph.pop(node1, None)\n",
    "        #TODO raise exception if pop fail => return None\n",
    "def random_failure(my_graph, limit, step):\n",
    "    '''\n",
    "    random_failure(my_graph, limit, step)\n",
    "    \n",
    "    Return the evolution of the largest connected component size according to the number of nodes that are \n",
    "    deleted from the graph randomly with at most 'limit' nodes deleted with a step of 'step'\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            limit (int) : the total number of nodes that will be deleted\n",
    "            step (int) : number of nodes to be deleted at each step\n",
    "        Returns\n",
    "            my_data (dictionary) : dictionary which key are the numbers of nodes removed and the value the\n",
    "            size of the largest connected component when the corresponding number of nodes have been deleted \n",
    "            from the graph\n",
    "    \n",
    "    '''\n",
    "    my_data = {}\n",
    "    nodes_left = list(my_graph.keys())\n",
    "    for key in range(step, limit, step):\n",
    "        # generation of the nodes to be deleted from the graph\n",
    "        to_delete = []\n",
    "        for i in range(step):\n",
    "            to_delete.append(nodes_left.pop(randint(0, len(nodes_left) - 1)))\n",
    "        delete_node(my_graph, to_delete)\n",
    "        my_data[key] = bfs(my_graph)\n",
    "    return my_data\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    inet_graph = load_clean_graph(inet)\n",
    "    my_data = random_failure(inet_graph, 100, 10)\n",
    "    print(json.dumps(my_data, indent = 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: robustness to targeted (degree-based) failures "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "In this question, we do the same as in the previous question, except for the fact that nodes are not chosen randomly, but by decreasing degree order.\n",
    "\n",
    "Suggested implementation:\n",
    "\n",
    "- create a function that outputs a list of nodes ordered by decreasing degree\n",
    "\n",
    "- then follow the same principle as in the previous question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_order_nodes(my_graph):\n",
    "    '''\n",
    "    create_order_nodes(my_graph)\n",
    "     \n",
    "    Returns a list of nodes ordered by decreasing degree\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "        Return\n",
    "            nodes_ordered (list of int): list of the nodes sorted by decreasing degree\n",
    "    '''\n",
    "    my_degrees = {}\n",
    "    for node in my_graph:\n",
    "        my_degrees[node] = len(my_graph[node])\n",
    "    my_degrees = sorted(my_degrees.items(), key=lambda item: item[1], reverse = True)\n",
    "    return [node for node, degree in my_degrees]\n",
    "\n",
    "def target_failure(my_graph, limit, step):\n",
    "    '''\n",
    "    target_failure(my_graph, limit, step)\n",
    "    \n",
    "    Return the evolution of the largest connected component size according to the number of nodes that are \n",
    "    deleted from the graph by decreasing degree\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            limit (int) : the total number of nodes that will be deleted\n",
    "            step (int) : number of nodes to be deleted at each step\n",
    "        Returns\n",
    "            my_data (dictionary) : dictionary which key are the numbers of nodes removed and the value the size \n",
    "            of the largest connected component when the corresponding number of nodes have been deleted from \n",
    "            the graph\n",
    "    '''\n",
    "    my_data = {}\n",
    "    nodes_left = create_order_nodes(my_graph)\n",
    "    for key in range(step, limit, step):\n",
    "        # generation of the nodes to be deleted from the graph\n",
    "        to_delete = []\n",
    "        for i in range(step):\n",
    "            to_delete.append(nodes_left.pop(0))\n",
    "        #print(to_delete)\n",
    "        delete_node(my_graph, to_delete)\n",
    "        my_data[key] = bfs(my_graph)\n",
    "    return my_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    inet_graph = load_clean_graph(inet)\n",
    "    my_data = target_failure(inet_graph, 5, 1)\n",
    "    print(json.dumps(my_data, indent = 4))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "Compare the two curves (random deletions and targeted deletions): are they different? What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(file_name, limit, step):\n",
    "    '''\n",
    "    plot_curves(file_name, limit, step)\n",
    "    \n",
    "    Plot the evolution of the largest connected component of the graph stored in 'file_name' according to the nodes\n",
    "    that are deleted which is at most 'limit' and with a sampling rate fo 'step' nodes, two plots will be printed,\n",
    "    a red curve representing the evolution with random deletions and a blue curve representing the evolution with\n",
    "    deletion of nodes by decreasing degree.\n",
    "        Parameters :\n",
    "            file_name (string) : the name of the file that contain the graph\n",
    "            limit (int) : the upper bound limit of nodes deletion\n",
    "            step (int) : the sampling rate i.e how many nodes are deleted at each step\n",
    "        Returns:\n",
    "    '''\n",
    "    inet_graph = load_clean_graph(file_name)\n",
    "    dic_target = target_failure(inet_graph, limit,step)\n",
    "    inet_graph = load_clean_graph(file_name)\n",
    "    dic_random = random_failure(inet_graph, limit,step)\n",
    "    x, y = dic_target.keys(), dic_target.values()\n",
    "    x1, y1 = dic_random.keys(), dic_random.values()\n",
    "    plt.plot(x1,y1, color='red') \n",
    "    plt.plot(x,y, color='blue')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    plot_curves(inet, 8000,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
