{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab4-5 (Student version): standard graph models\n",
    "\n",
    "We can use the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import sys\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lab work will spread over sessions 4 and 5. \n",
    "\n",
    "Session 4 should focus on making sure that the codes of previous sessions work correctly (ex.1) and on testing them on an Erdös-Rényi model (ex.2).\n",
    "\n",
    "Session 5 should focus on the two other models (ex.3 and ex.4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Preliminary work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "Download the graph http://lioneltabourier.fr/documents/as_caida.txt and load it in memory as a dictionary of lists (as usual). This graph is a partial map of the Internet at the AS level as obtained using BGP tables during the CAIDA project in 2007. It will be used during the rest of this practical work. \n",
    "\n",
    "Apply the codes seen in the previous labs to:\n",
    "- count its number of nodes and links, \n",
    "- plot its degree distribution,\n",
    "- compute its number of triangles,\n",
    "- give an approximation of its diameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_graph(input_name, output_name = None):\n",
    "    '''\n",
    "    load_clean_graph(input_name, output_name = None)\n",
    "    \n",
    "    Delete self-loops and duplicated edges existing in the graph and writes it in a new test file\"\n",
    "        Parameters:\n",
    "            input_name (string) : name of the file storing the graph with self loops and duplicated edges\n",
    "            output_name (string) (optional) : name of the file that will store the graph without self \n",
    "            loops and duplicated edges. If no output is defined the new graph will not be stored in a file\n",
    "        Returns:\n",
    "            my_graph (dictionary of lists) : the graph without self loops and duplicated edges\n",
    "    '''\n",
    "    my_graph = {}\n",
    "    if output_name is not None:\n",
    "        output_file = open(output_name, \"w\")\n",
    "    with open(input_name, \"r\") as input_file:\n",
    "        for line in input_file:\n",
    "\n",
    "            if line[0] != \"#\":\n",
    "                line = line.split()\n",
    "                node1 = int(line[0])\n",
    "                node2 = int(line[1])\n",
    "                if node1 != node2:\n",
    "                    if node1 in my_graph:\n",
    "                        if node2 not in my_graph[node1]:\n",
    "                            my_graph[node1].append(node2)\n",
    "                            if output_name is not None:\n",
    "                                output_file.write(f\"{node1} {node2}\\n\")\n",
    "                    else:\n",
    "                        my_graph[node1] = [node2]\n",
    "                    if node2 in my_graph:\n",
    "                        if node1 not in my_graph[node2]:\n",
    "                            my_graph[node2].append(node1)\n",
    "                            if output_name is not None:\n",
    "                                output_file.write(f\"{node2} {node1}\\n\")\n",
    "                    else:\n",
    "                        my_graph[node2] = [node1]\n",
    "    if output_name is not None:\n",
    "        output_file.close()\n",
    "    return my_graph\n",
    "    \n",
    "def node_link(file_name):\n",
    "    '''\n",
    "    node_link(file_name)\n",
    "    \n",
    "    Returns the number of edges and the number of nodes in the graph stored in 'file_name'\n",
    "        Parameters:\n",
    "            file_name(string) : the name of the file storing the graph\n",
    "        Returns:\n",
    "            node_count, link_count (int, int) : a tuple containing the number of nodes and the number of links in \n",
    "            the graph\n",
    "    '''\n",
    "    node_set = set()\n",
    "    node_count = 0\n",
    "    link_count = 0\n",
    "    with open(file_name, \"r\") as my_file:\n",
    "        for line in my_file:\n",
    "            if line[0] != \"#\": # supposing that comments start with a '#' symbol\n",
    "                line = line.split() # supposing a space between two nodes\n",
    "                node1 = int(line[0]) # supposing that nodes are numbers formated in file\n",
    "                node2 = int(line[1])\n",
    "                link_count += 1 # if a same link appears several times, it will be counted as many times\n",
    "                if node1 not in node_set:\n",
    "                    node_set.add(node1)\n",
    "                    node_count += 1\n",
    "                if node2 not in node_set:\n",
    "                    node_set.add(node2)\n",
    "                    node_count +=1  \n",
    "    return node_count, link_count\n",
    "\n",
    "def degree_dist(my_graph):\n",
    "    '''\n",
    "    degree_dist(my_graph)\n",
    "    \n",
    "    Computes the degree distribution of a graph\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "        Returns:\n",
    "            my_degree_dist (dictionary) : a dictionary wich key are the degrees that appear in the graph and \n",
    "            the values are the number of occurences\n",
    "    '''\n",
    "    my_degree_dist = {}\n",
    "    for node in my_graph:\n",
    "        node_degree = len(my_graph[node])\n",
    "        if node_degree in my_degree_dist:\n",
    "            my_degree_dist[node_degree] += 1\n",
    "        else:\n",
    "            my_degree_dist[node_degree] = 1\n",
    "    return my_degree_dist\n",
    "\n",
    "def plot_degree_dist(my_graph, log = True, limits = (0.5, 10000, 0.5, 10000), my_legend = \"Curve\"):\n",
    "    '''\n",
    "    plot_degree_dist(my_graph)\n",
    "    \n",
    "    Plot the degree distribution in log scale\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            log (boolean) (default = True): Plotting the graph with a axis in log scale\n",
    "            limits (int, int, int, int) (default = (0.5,10000,0.5,10000)) : the limits of the plot with the following format (xmin, xmax, ymin, ymax)\n",
    "        Returns\n",
    "    '''\n",
    "    my_degree_dist = degree_dist(my_graph)\n",
    "    xmin, xmax, ymin, ymax = limits\n",
    "    if log:\n",
    "        plt.xscale('log')\n",
    "        plt.yscale('log')\n",
    "        plt.xlim([xmin, xmax])\n",
    "        plt.ylim([ymin, ymax])\n",
    "    s = plt.scatter(my_degree_dist.keys(), my_degree_dist.values(), label = my_legend)\n",
    "    plt.legend()\n",
    "\n",
    "def triangle(my_graph):\n",
    "    '''\n",
    "    triangle(my_graph)\n",
    "    \n",
    "    Returns the number of triangles in the graph 'my_graph'\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "        Returns:\n",
    "            triangle_count (int) : the number of triangles in the graph\n",
    "    '''\n",
    "    triangle_count = 0\n",
    "    for node1 in my_graph:\n",
    "        for node2 in my_graph[node1]:\n",
    "            if node1 < node2:\n",
    "                for node3 in my_graph[node1]:\n",
    "                    if node3 in my_graph[node2]: # node3 in N(node1) and N(node2)\n",
    "                        if node2 < node3:\n",
    "                            triangle_count += 1\n",
    "    return triangle_count\n",
    "\n",
    "def distances(my_graph, source_node):\n",
    "    '''\n",
    "    distances(my_graph, source_node)\n",
    "    \n",
    "    Returns the distances of each node to the source node as a dictionary\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            source_node (int) : the node from which we will compute the distances\n",
    "        Returns:\n",
    "            my_distances : A dictionary which keys are the nodes and the values are the distances from the \n",
    "            key to 'source_node'\n",
    "    '''\n",
    "    my_queue = [source_node]\n",
    "    my_distances = {}\n",
    "    for node in my_graph:\n",
    "        my_distances[node] = -1\n",
    "    my_distances[source_node] = 0\n",
    "    while my_queue:\n",
    "        node1 = my_queue.pop(0)\n",
    "        for node2 in my_graph[node1]:\n",
    "            if my_distances[node2] == -1:\n",
    "                my_queue.append(node2)\n",
    "                my_distances[node2] = my_distances[node1] + 1\n",
    "    return my_distances\n",
    "\n",
    "def diameter(my_graph, sample_size):\n",
    "    '''\n",
    "    diameter(my_graph, sample_size)\n",
    "    \n",
    "    Compute an approximate diameter of the  graph 'my_graph' by running a bfs algorithm on a sample of nodes \n",
    "    and taking the max of the distances\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "            sample_size (int) : the number of nodes in the graph that will be used to find the diameter\n",
    "        Returns:\n",
    "            my_diameter (int) : the approximate maximum distance in the graph\n",
    "    '''\n",
    "    my_diameter = -1\n",
    "    nodes = list(my_graph.keys())\n",
    "    for i in range(sample_size):\n",
    "        my_distances = distances(my_graph, nodes.pop(random.randint(0,len(nodes) - 1)))\n",
    "        my_diameter = max(my_diameter, max(list(my_distances.values())))\n",
    "    return my_diameter\n",
    "\n",
    "def add_link(my_link, my_graph):\n",
    "    '''\n",
    "    add_link((node1, node2), my_graph)\n",
    "    \n",
    "    Add the link ('node1', 'node2') in the graph 'my_graph'\n",
    "        Parameters:\n",
    "            (node1, node2) (int, int) : the link  that will be added\n",
    "            my_graph (dictionary of lists) : the graph that will contain the link\n",
    "        Returns:    \n",
    "    '''\n",
    "    node1, node2 = my_link\n",
    "    if node1 in my_graph:\n",
    "        my_graph[node1].append(node2)\n",
    "    else:\n",
    "        my_graph[node1] = [node2]\n",
    "    if node2 in my_graph:\n",
    "        my_graph[node2].append(node1)\n",
    "    else:\n",
    "        my_graph[node2] = [node1]\n",
    "    return\n",
    "\n",
    "caida = 'graphs/as_caida.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__'  and '__file__' not in globals():\n",
    "    caida_graph = load_clean_graph(caida)\n",
    "    count_node, count_link = node_link(caida)\n",
    "    print(f\"Caida \\n\\tNodes : {count_node}, Links : {count_link}\")\n",
    "    plot_degree_dist(caida_graph, log = True)\n",
    "    print(f\"\\tTriangles : {triangle(caida_graph)}\")\n",
    "    print(f\"\\tDiameter : {diameter(caida_graph,100)}\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Erdös-Rényi model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create an Erdös-Rényi graph with the same number of nodes and links as the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def erdos(node_count, link_count):\n",
    "    '''\n",
    "    erdos(node_count, link_count)\n",
    "    \n",
    "    Generates a graph with 'node_count' nodes and 'link_count' links\n",
    "        Parameters:\n",
    "            node_count (int)\n",
    "            link_count (int)\n",
    "        Returns:\n",
    "            my_graph (dictionary of lists) : \n",
    "    '''\n",
    "    my_graph = {}\n",
    "    for node in range(node_count):\n",
    "        my_graph[node] = []\n",
    "    current_link_count = 0\n",
    "    while current_link_count <= link_count:\n",
    "        node1 = random.randint(0, node_count -1)\n",
    "        node2 = random.randint(0, node_count -1)\n",
    "        link_exists = node1 in my_graph and node2 in my_graph\n",
    "        link_exists = link_exists and node1 in my_graph[node2] # node 1 is a neighbour of node 2\n",
    "        link_exists = link_exists and node2 in my_graph[node1] # node 2 is a neighbour of node 1\n",
    "        if not link_exists:\n",
    "            add_link((node1, node2), my_graph)\n",
    "            current_link_count += 1\n",
    "    return my_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "erdos_graph = erdos(count_node,count_link)\n",
    "\n",
    "print(json.dumps(erdos_graph , indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Compare its degree distribution, its number of triangles, its approximate diameter (of the largest component) to the one of the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Erdos\")\n",
    "plot_degree_dist(erdos_graph, log = False, my_legend = \"erdos\")\n",
    "print(f\"\\tTriangles : {triangle(erdos_graph)}\")\n",
    "print(f\"\\tDiameter : {diameter(erdos_graph,100)}\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On observe une diminution importante du nombre de triangles dans le graphe généré par le modèle Erdös-Rény, le diamètre n'a pas changé (l'ordre de grandeur est le même). La majorité des degrés se rapprochent d'une moyenne égale à 3. Cela s'explique par les propriétés d'un graphe généré par le modèle d'Erdös-Rény. Ce type de graphe possède une distribution de degré homogène, un coefficient de clustering faible et des distances entre noeud faibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Barabasi-Albert model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Create a Barabasi-Albert graph with a number of links and nodes comparable to the original graph. We remind that in a BA model with $n$ nodes, the number of links $m$ is roughly equal to $\\alpha n$ where $ \\alpha $ is the parameter of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def sum_degree(my_graph):\n",
    "    '''\n",
    "    sum_degree(my_graph)\n",
    "    \n",
    "    Compute the sum of the degree of the nodes in the graph 'my_graph'\n",
    "        Parameters:\n",
    "            my_graph (dictionary of lists)\n",
    "        Returns:\n",
    "            my_sum_degree (int) : the sum of the degree of the nodes\n",
    "    '''\n",
    "    my_sum_degree = 0\n",
    "    for node in my_graph:\n",
    "        my_sum_degree += len(my_graph[node])\n",
    "    return my_sum_degree\n",
    "def barabasi(graph_size, my_graph, alpha):\n",
    "    '''\n",
    "    barabasi(graph_size, base_graph, alpha)\n",
    "    \n",
    "    Generates a Barabasi-Albert graph starting with the graph 'base_graph' and adding nodes until\n",
    "    the graph's size equal to 'graph_size'. The added nodes should have degree equal to 'alpha'\n",
    "        Parameters:\n",
    "            graph_size (int) : the size of the graph that will be generated\n",
    "            base_graph (dictionary of list): the graph that will be used as the base\n",
    "            alpha (int): the degree of the nodes that will be added\n",
    "        Returns\n",
    "    '''\n",
    "    base_graph = copy.deepcopy(my_graph)\n",
    "    origin_size = len(base_graph)\n",
    "    for new_node in range(origin_size + 1, graph_size + 1):\n",
    "        \n",
    "        print(f\"\\r Loading the barabasi graph : {new_node} / {graph_size}\",end = \"\", flush = True)\n",
    "        node_odd = []\n",
    "        my_sum_degree = sum_degree(base_graph)\n",
    "        cumul = 0\n",
    "        for node in base_graph: # Compute the odds for each node to be linked to the new node\n",
    "            cumul += len(base_graph[node]) / my_sum_degree\n",
    "            node_odd.append((node, cumul))\n",
    "        base_graph[new_node] = [] # New node added to graph\n",
    "        degree_new_node = 0\n",
    "        while degree_new_node < alpha:\n",
    "            tmp = random.uniform(0,1)\n",
    "            neighbour_node = None\n",
    "            for (node, odd) in node_odd:\n",
    "                if tmp < odd:\n",
    "                    neighbour_node = node\n",
    "                    break\n",
    "            link_exist = neighbour_node in base_graph[new_node] and new_node in base_graph[neighbour_node] \n",
    "            if not link_exist:\n",
    "                add_link((new_node, neighbour_node), base_graph)\n",
    "                degree_new_node += 1\n",
    "    return base_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "    my_erdos = erdos(100,100)\n",
    "    print(\"Base of the graph generated\")\n",
    "    n_barabasi = 2647\n",
    "    alpha = 2\n",
    "    my_barabasi = barabasi(n_barabasi, my_erdos, alpha)\n",
    "    print(json.dumps(my_barabasi, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Question 5\n",
    "\n",
    "Compare its degree distribution, its number of triangles, its approximate diameter (of the largest component) to the one of the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__' and '__file__' not in globals():\n",
    "    #print(json.dumps(degree_dist(my_barabasi), indent = 4))\n",
    "    plot_degree_dist(my_barabasi, my_legend = \"Barabasi\")\n",
    "    \n",
    "    print(f\"\\t Triangles : {triangle(my_barabasi)}\")\n",
    "    print(f\"\\t Diameter : {diameter(my_barabasi, 100)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "On observe un nombre très faible de triangle par rapport au graphe original et un diamètre assez similaire au graphe initial. La distribution de degré est cependant identique. Le modèle de Barabasi Albert est un modèle sans échelle, les graphes suivant ce modèle possède un coefficient de clustering failbe voire nulle expliquant la faible valeur du nombre de triangles, des distances entre noeuds faibles expliquant le diamètre et une distributino de degré sans échelle c'est-à-dire une droite suivante une pente égale au pramètre alpha en utilisant une échelle logarithmique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Watts-Strogatz model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "Create a regular graph with a number of nodes $n$ equals to the one of the initial CAIDA graph. We have these constraints:\n",
    "\n",
    "* all nodes of a regular graph have the same degree $k$, choose $k$ so that the number $m$ of edges is close to the one of the CAIDA graph,\n",
    "\n",
    "* each node is connected to the nodes with the closest index, for example, if $k=6$, node $i$ will be connected to nodes $ i-1 $, $ i-2 $, $ i-3$ and $ i+1 $, $ i+2 $, $ i+3 $.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regular_graph(node_count, node_degree):\n",
    "    '''\n",
    "    Generates a regular graph with a number of nodes equal to 'node_count', each node have the same degree equal to\n",
    "    'node_degree'\n",
    "        Parameters:\n",
    "            node_count (int): the number of nodes in the generated graph\n",
    "            node_degree (int) : the degree of each nodes in the generated graph\n",
    "        Returns:\n",
    "            my_graph (dictionary of lists): a graph with 'node_count' nodes and each node have te same degree 'k'\n",
    "    '''\n",
    "    my_graph = {}\n",
    "    for node in range(node_count):\n",
    "        my_graph[node] = []\n",
    "        for neighbour in range(- round(node_degree / 2) + node, round(node_degree / 2) + 1 + node):\n",
    "            if neighbour != node:\n",
    "                my_graph[node].append(neighbour % node_count)\n",
    "    return my_graph\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    my_watts = regular_graph(10000, 4)\n",
    "    print(json.dumps(my_watts, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "\n",
    "Starting from the graph created in the previous question, generate Watts-Strogatz models with several values of the parameter $p$: 0.01, 0.1, 0.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "def watts(base_graph, p):\n",
    "    '''\n",
    "    watts(base_graph, p)\n",
    "    \n",
    "    Generates a graph according to Watts-Strogatz model\n",
    "        Parameters:\n",
    "            base_graph (dictionary of lists)\n",
    "            p (float)\n",
    "        Returns\n",
    "    '''\n",
    "    new_graph = copy.deepcopy(base_graph)\n",
    "    for node1 in base_graph:\n",
    "        for node2 in base_graph[node1]: # going through all links in the graph\n",
    "            if node1 < node2:\n",
    "                #print(f\"Processing {node1} {node2}\")\n",
    "                loop = True\n",
    "                #multi_edge = False\n",
    "                while loop:\n",
    "                    ri_node = node1\n",
    "                    rj_node = node2\n",
    "                    ri = random.uniform(0,1)\n",
    "                    rj = random.uniform(0,1)\n",
    "                    if ri < p: \n",
    "                        ri_node = random.randint(0, len(base_graph) - 1)\n",
    "                        while ri_node == node1:\n",
    "                            ri_node = random.randint(0, len(base_graph) - 1)\n",
    "                    if rj < p:\n",
    "                        rj_node = random.randint(0, len(base_graph) - 1)\n",
    "                        while rj_node == node1:\n",
    "                            rj_node = random.randint(0, len(base_graph) - 1)\n",
    "                    loop = ri_node == rj_node\n",
    "                    multi_edge = (ri_node != node1 or ri_node != node2) and ri_node in new_graph[rj_node] and rj_node in new_graph[ri_node]\n",
    "                new_graph[node1].remove(node2)\n",
    "                new_graph[node2].remove(node1)\n",
    "                #print(f\"linking {ri_node} {rj_node}\")\n",
    "                add_link((ri_node, rj_node), new_graph)\n",
    "    return new_graph   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    my_watts = regular_graph(10000, 4)\n",
    "    watts(my_watts, 0.01)\n",
    "    print(json.dumps(my_watts, indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "\n",
    "Compare their degree distribution, their number of triangles, their approximate diameter (of the largest component) to the one of the original graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\" and \"__file__\" not in globals():\n",
    "    #p1 = 0.01; p2 = 0.1; p3 = 0.3; \n",
    "    node_count = 26450; k = 6; diameter_sample = 100\n",
    "    probs = [0.01, 0.1, 0.3]\n",
    "    my_regular = regular_graph(node_count, k)\n",
    "\n",
    "    for p in probs:\n",
    "        print(f\"Model Watts p = {p}\")\n",
    "        my_watts = watts(my_regular, p)\n",
    "        print(f\"\\tTriangle : {triangle(my_watts)}\")\n",
    "        print(f\"\\tDiameter : {diameter(my_watts,diameter_sample)}\")\n",
    "        plot_degree_dist(my_graph = my_watts, log = False, my_legend = f\"p = {p}\")\n",
    "    \n",
    "    \n",
    "    #print(my_watts)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Avec ce modèle, on observe un nombre élevé de triangles, un diamètre du même ordre de grandeur que le graphe original et une distribution de degré homogène. Ceci s'explique par le fait que lorsque le paramètre p est petit, le nombre de reconnexion est faible, le nombre de triangles qui était élevé dans le graphe régulier n'a donc pas changé et au fur et à mesure que le taux de reconnexion p augmente, les triangles du graphe régulier disparaissent. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
